{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fcee0e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a4001fe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow\n",
    "\n",
    "\n",
    "print(tensorflow.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2bb4d58",
   "metadata": {},
   "source": [
    "## 데이타 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eba45405",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#conversation_lines = os.path.join('~/aiffel/transformer_chatbot/data/ChatbotData.csv')\n",
    "conversation_lines = os.getenv('HOME')+'/aiffel/transformer_chatbot/data/ChatbotData.csv'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a454ce74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# 전처리 함수\n",
    "def preprocess_sentence(sentence):\n",
    "\n",
    "  # 소문자화 & 공백 제거 (한국어는 대소문자 의미 없음, 하지만 영어 혼합 대비)\n",
    "  sentence = sentence.lower().strip()\n",
    "\n",
    "  # 단어와 구두점(punctuation) 사이의 거리를 만듭니다.\n",
    "  # 예를 들어서 \"I am a student.\" => \"I am a student .\"와 같이\n",
    "  # student와 온점 사이에 거리를 만듭니다.\n",
    "  sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)  # 구두점 앞뒤로 공백추가\n",
    " \n",
    "  # 허용된 문자 외 제거 (한글, 영어, 숫자, 구두점)\n",
    "  sentence = re.sub(r\"[^가-힣a-zA-Z0-9?.!,]+\", \" \", sentence)\n",
    "  \n",
    "  # 다중 공백 정리\n",
    "  sentence = re.sub(r'[\" \"]+', \" \", sentence)        # 여러개의 공백을 하나로\n",
    "  \n",
    "  return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b507458b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사용할 샘플의 최대 개수\n",
    "MAX_SAMPLES = 20000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5974472a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 샘플의 최대 허용 길이 또는 패딩 후의 최종 길이\n",
    "MAX_LENGTH = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af8d9790",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 질문과 답변의 쌍인 데이터셋을 구성하기 위한 데이터 로드 함수\n",
    "def load_conversations():\n",
    "\n",
    "  inputs, outputs = [], []\n",
    "  with open(conversation_lines, 'r') as file:\n",
    "    lines = file.readlines()\n",
    "    \n",
    "    # 첫 줄은 헤더니까 건너뜁니다\n",
    "    for line in lines[1:]:\n",
    "        parts = line.strip().split(',')\n",
    "        if len(parts) >= 2:\n",
    "            question, answer = parts[0], parts[1]\n",
    "            inputs.append(preprocess_sentence(question))\n",
    "            outputs.append(preprocess_sentence(answer))\n",
    "\n",
    "    if len(inputs) >= MAX_SAMPLES:\n",
    "        return inputs, outputs\n",
    "  return inputs, outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6a48cd66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 질문과 답변의 쌍인 데이터셋을 구성하기 위한 데이터 로드 함수\n",
    "import csv\n",
    "\n",
    "def load_conversations_csv():\n",
    "\n",
    "  inputs, outputs = [], []\n",
    "  with open(conversation_lines, 'r') as file:\n",
    "        \n",
    "    reader = csv.reader(file)\n",
    "    next(reader)  # 첫 줄은 헤더이므로 건너뜀\n",
    "    \n",
    "    for row in reader:\n",
    "        if len(row) >= 2:\n",
    "            question, answer = row[0], row[1]\n",
    "            inputs.append(preprocess_sentence(question))\n",
    "            outputs.append(preprocess_sentence(answer))\n",
    "\n",
    "        if len(inputs) >= MAX_SAMPLES:\n",
    "            break\n",
    "        \n",
    "  \n",
    "  return inputs, outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3c403608",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플 수 : 11823\n",
      "전체 샘플 수 : 11823\n"
     ]
    }
   ],
   "source": [
    "# 데이터를 로드하고 전처리하여 질문을 questions, 답변을 answers에 저장합니다.\n",
    "#questions, answers = load_conversations()\n",
    "questions, answers = load_conversations_csv()\n",
    "print('전체 샘플 수 :', len(questions))\n",
    "print('전체 샘플 수 :', len(answers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "67100bc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전처리 후의 22번째 질문 샘플: 가스비 장난 아님\n",
      "전처리 후의 22번째 답변 샘플: 다음 달에는 더 절약해봐요 . \n"
     ]
    }
   ],
   "source": [
    "print('전처리 후의 22번째 질문 샘플: {}'.format(questions[21]))\n",
    "print('전처리 후의 22번째 답변 샘플: {}'.format(answers[21]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa160ba5",
   "metadata": {},
   "source": [
    "1) TensorFlow Datasets SubwordTextEncoder 를 토크나이저로 사용한다.  단어보다 더 작은 단위인 Subword를 기준으로 토크나이징하고,  각 토큰을 고유한 정수로 인코딩 한다.\n",
    "2) 각 문장을 토큰화하고 각 문장의 시작과 끝을 나타내는 START_TOKEN 및 END_TOKEN을 추가한다.\n",
    "3) 최대 길이 MAX_LENGTH 인 40을 넘는 문장들은 필터링한다.\n",
    "4) MAX_LENGTH보다 길이가 짧은 문장들은 40에 맞도록 패딩 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "130b65c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "\n",
    "\n",
    "# 질문과 답변 데이터셋에 대해서 Vocabulary 생성\n",
    "tokenizer = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(questions + answers, target_vocab_size=2**13)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8e3178de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START_TOKEN의 번호 : [8165]\n",
      "END_TOKEN의 번호 : [8166]\n",
      "8167\n"
     ]
    }
   ],
   "source": [
    "# 시작 토큰과 종료 토큰에 고유한 정수를 부여합니다.\n",
    "START_TOKEN, END_TOKEN = [tokenizer.vocab_size], [tokenizer.vocab_size + 1]\n",
    "\n",
    "print('START_TOKEN의 번호 :' ,[tokenizer.vocab_size])\n",
    "print('END_TOKEN의 번호 :' ,[tokenizer.vocab_size + 1])\n",
    "\n",
    "# 시작 토큰과 종료 토큰을 고려하여 +2를 하여 단어장의 크기를 산정합니다.\n",
    "VOCAB_SIZE = tokenizer.vocab_size + 2\n",
    "print(VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fda6ab07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정수 인코딩, 최대 길이를 초과하는 샘플 제거, 패딩\n",
    "def tokenize_and_filter(inputs, outputs):\n",
    "  tokenized_inputs, tokenized_outputs = [], []\n",
    "  \n",
    "  for (sentence1, sentence2) in zip(inputs, outputs):\n",
    "    # 정수 인코딩 과정에서 시작 토큰과 종료 토큰을 추가\n",
    "    sentence1 = START_TOKEN + tokenizer.encode(sentence1) + END_TOKEN\n",
    "    sentence2 = START_TOKEN + tokenizer.encode(sentence2) + END_TOKEN\n",
    "\n",
    "    # 최대 길이 40 이하인 경우에만 데이터셋으로 허용\n",
    "    if len(sentence1) <= MAX_LENGTH and len(sentence2) <= MAX_LENGTH:\n",
    "      tokenized_inputs.append(sentence1)\n",
    "      tokenized_outputs.append(sentence2)\n",
    "  \n",
    "  # 최대 길이 40으로 모든 데이터셋을 패딩\n",
    "  tokenized_inputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "      tokenized_inputs, maxlen=MAX_LENGTH, padding='post')\n",
    "  tokenized_outputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "      tokenized_outputs, maxlen=MAX_LENGTH, padding='post')\n",
    "  \n",
    "  return tokenized_inputs, tokenized_outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "91743682",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어장의 크기 : 8167\n",
      "필터링 후의 질문 샘플 개수: 11823\n",
      "필터링 후의 답변 샘플 개수: 11823\n"
     ]
    }
   ],
   "source": [
    "questions, answers = tokenize_and_filter(questions, answers)\n",
    "print('단어장의 크기 :',(VOCAB_SIZE))\n",
    "print('필터링 후의 질문 샘플 개수: {}'.format(len(questions)))\n",
    "print('필터링 후의 답변 샘플 개수: {}'.format(len(answers)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dae74c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = 20000\n",
    "\n",
    "# 디코더는 이전의 target을 다음의 input으로 사용합니다.\n",
    "# 이에 따라 outputs에서는 START_TOKEN을 제거하겠습니다.\n",
    "dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    {\n",
    "        'inputs': questions,\n",
    "        'dec_inputs': answers[:, :-1]  # 디코더 입력 (교사 강요용),  END_TOKEN 제거\n",
    "    },\n",
    "    {\n",
    "        'outputs': answers[:, 1:]      # 디코더 출력 (정답), START_TOKEN 제거\n",
    "    },\n",
    "))\n",
    "\n",
    "dataset = dataset.cache()                       # 메모리에 캐싱, 에포크가 반복될때 디스크 읽기/파싱 비용을 줄임\n",
    "dataset = dataset.shuffle(BUFFER_SIZE)          # 무작위로 섞지 않으면, 학습이 데이터 순서에 의존하게 되어 과적합 위험이 높아짐\n",
    "dataset = dataset.batch(BATCH_SIZE)             # 배치로 묶어서 모델에 한번에 전달\n",
    "dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE) # GPU가 학습하는 동안 CPU가 다음 배치를 미리 준비\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c917458",
   "metadata": {},
   "source": [
    "## 공통 함수"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a579bf",
   "metadata": {},
   "source": [
    "**포지셔널 인코딩 레이어**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4aac24ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 포지셔널 인코딩 레이어\n",
    "# d_model : 임베딩 벡터의 차원,  각 단어 벡터의 차원 (예: 512)\n",
    "# position: 입력 문장에서의 임베딩 벡터의 위치, 시퀀스의 최대 길이 \n",
    "# i       : 임베딩 벡터 내의 차원의 인덱스를 의미\n",
    "class PositionalEncoding(tf.keras.layers.Layer):\n",
    "\n",
    "  def __init__(self, position, d_model):                             \n",
    "    super(PositionalEncoding, self).__init__()\n",
    "    self.pos_encoding = self.positional_encoding(position, d_model)           # 미리 전체 포지션 인코딩을 계산해서 저장\n",
    "\n",
    "  def get_angles(self, position, i, d_model):\n",
    "    angles = 1 / tf.pow(10000, (2 * (i // 2)) / tf.cast(d_model, tf.float32)) # 공식에 따라 포지션과 차원 인덱스에 따라 각도를 계산 \n",
    "    return position * angles\n",
    "\n",
    "  def positional_encoding(self, position, d_model):\n",
    "    # 각도 배열 생성\n",
    "    angle_rads = self.get_angles(\n",
    "        position=tf.range(position, dtype=tf.float32)[:, tf.newaxis],\n",
    "        i=tf.range(d_model, dtype=tf.float32)[tf.newaxis, :],\n",
    "        d_model=d_model)\n",
    "\n",
    "    # 배열의 짝수 인덱스에는 sin 함수 적용\n",
    "    sines = tf.math.sin(angle_rads[:, 0::2])\n",
    "    # 배열의 홀수 인덱스에는 cosine 함수 적용\n",
    "    cosines = tf.math.cos(angle_rads[:, 1::2])\n",
    "\n",
    "    # sin과 cosine이 교차되도록 재배열\n",
    "    pos_encoding = tf.stack([sines, cosines], axis=0)\n",
    "    pos_encoding = tf.transpose(pos_encoding,[1, 2, 0]) \n",
    "    pos_encoding = tf.reshape(pos_encoding, [position, d_model])\n",
    "\n",
    "    pos_encoding = pos_encoding[tf.newaxis, ...]\n",
    "    return tf.cast(pos_encoding, tf.float32)\n",
    "\n",
    "  def call(self, inputs):\n",
    "    return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]  # 입력 텐서에 위치 인코딩을 더해줌\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fb54170",
   "metadata": {},
   "source": [
    "**어텐션**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "696ed43f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 스케일드 닷 프로덕트 어텐션 함수\n",
    "def scaled_dot_product_attention(query, key, value, mask):\n",
    "  # 어텐션 가중치는 Q와 K의 닷 프로덕트\n",
    "\n",
    "  matmul_qk = tf.matmul(query, key, transpose_b=True)  # 행렬 곱셈(matrix multiplication), key를 transpose함\n",
    "  # Q: (batch_size, num_heads, seq_len_q, depth)\n",
    "  # K: (batch_size, num_heads, seq_len_k, depth)\n",
    "  # QK^T → shape: (batch_size, num_heads, seq_len_q, seq_len_k)\n",
    "\n",
    "  # 가중치를 정규화\n",
    "  depth = tf.cast(tf.shape(key)[-1], tf.float32)       # key 마지막 차원의 크기를 float32로 변환 (부동소수점자료형)\n",
    "  logits = matmul_qk / tf.math.sqrt(depth)             # 차원수로 scaling하는 작업\n",
    "\n",
    "  # 패딩에 마스크 추가\n",
    "  # 마스크된 곳에는 아주 큰 마이너스 값으로 변경하여, 사용되지 않게.\n",
    "  if mask is not None:\n",
    "    logits += (mask * -1e9)\n",
    "\n",
    "  # softmax적용\n",
    "  attention_weights = tf.nn.softmax(logits, axis=-1)\n",
    "    \n",
    "  # attention_logits.shape = (batch_size, num_heads, seq_len_q, seq_len_k)\n",
    "\n",
    "  # 최종 어텐션은 가중치와 V의 닷 프로덕트\n",
    "  output = tf.matmul(attention_weights, value)\n",
    "  # (seq_len_q, seq_len_k) @ (seq_len_k, depth) → (seq_len_q, depth)\n",
    "  # V: (batch_size, num_heads, seq_len_k, depth)\n",
    "  # output : (batch_size, num_heads, seq_len_q, depth)\n",
    "  return output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "77364fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "\n",
    "  def __init__(self, d_model, num_heads, name=\"multi_head_attention\"):\n",
    "    super(MultiHeadAttention, self).__init__(name=name)\n",
    "    self.num_heads = num_heads\n",
    "    self.d_model = d_model\n",
    "\n",
    "    assert d_model % self.num_heads == 0\n",
    "\n",
    "    self.depth = d_model // self.num_heads\n",
    "\n",
    "    self.query_dense = tf.keras.layers.Dense(units=d_model)\n",
    "    self.key_dense = tf.keras.layers.Dense(units=d_model)\n",
    "    self.value_dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "    self.dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "  def split_heads(self, inputs, batch_size):\n",
    "    inputs = tf.reshape(\n",
    "        inputs, shape=(batch_size, -1, self.num_heads, self.depth))\n",
    "    return tf.transpose(inputs, perm=[0, 2, 1, 3])\n",
    "\n",
    "  def call(self, inputs):\n",
    "    query, key, value, mask = inputs['query'], inputs['key'], inputs[\n",
    "        'value'], inputs['mask']\n",
    "    \n",
    "    # inputs.shape = [batch_size, seq_len, embedding_dim]\n",
    "    batch_size = tf.shape(query)[0]\n",
    "\n",
    "    # Q, K, V에 각각 Dense를 적용합니다\n",
    "    # (batch_size, seq_len, embedding_dim)\n",
    "    query = self.query_dense(query)\n",
    "    key = self.key_dense(key)\n",
    "    value = self.value_dense(value)\n",
    "\n",
    "    # 병렬 연산을 위한 머리를 여러 개 만듭니다\n",
    "    # (batch_size, num_heads, seq_len, projection_dim)\n",
    "    query = self.split_heads(query, batch_size)\n",
    "    key = self.split_heads(key, batch_size)\n",
    "    value = self.split_heads(value, batch_size)\n",
    "\n",
    "    # 스케일드 닷 프로덕트 어텐션 함수\n",
    "    scaled_attention = scaled_dot_product_attention(query, key, value, mask)\n",
    "    # shape : (batch_size, num_heads, seq_len_q, projection_dim)\n",
    "    scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
    "    # (batch_size, seq_len_q, num_heads, projection_dim)\n",
    "\n",
    "    # 어텐션 연산 후에 각 결과를 다시 연결(concatenate)합니다\n",
    "    # (batch_size, seq_len, embedding_dim)\n",
    "    concat_attention = tf.reshape(scaled_attention,\n",
    "                                  (batch_size, -1, self.d_model))\n",
    "\n",
    "    # 최종 결과에도 Dense를 한 번 더 적용합니다\n",
    "    outputs = self.dense(concat_attention)\n",
    "\n",
    "    return outputs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a237c38f",
   "metadata": {},
   "source": [
    "**패딩 마스크**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7828f2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#모델이 의미 없는 패딩 토큰에 주의를 빼앗기지 않도록 하기 위해 **마스킹(masking)**을 한다.\n",
    "def create_padding_mask(x):\n",
    "  mask = tf.cast(tf.math.equal(x, 0), tf.float32)   # [7, 6, 0, 0, 0] → [False, False, True, True, True]\n",
    "                                                    # Boolen 값을 float32로 변경 → [0.0, 0.0, 1.0, 1.0, 1.0]\n",
    "  # (batch_size, 1, 1, sequence length_k)\n",
    "  return mask[:, tf.newaxis, tf.newaxis, :]         # 차원을 확장해서, 어덴션 스코어와 잘 계산되게 맞추어줌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2b88e7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(create_padding_mask(tf.constant([[1, 2, 0, 3, 0], [0, 0, 0, 4, 5]])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a2828fa",
   "metadata": {},
   "source": [
    "**룩 어헤드 마스킹(Look-ahead masking, 다음 단어 가리기)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1237ace9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_look_ahead_mask(x):\n",
    "  # (batch_size, seq_len, dim)\n",
    "  seq_len = tf.shape(x)[1]\n",
    "  # 하삼각 행렬(lower triangular matrix)**을 생성\n",
    "    #  [[1, 0, 0],\n",
    "    #   [1, 1, 0],\n",
    "    #   [1, 1, 1]]\n",
    "  # mask = 1 - 하삼각 행렬  (자신보다 뒤에 있는 토큰에 1을 설정하는 마스크 )\n",
    "    #  [[0, 1, 1],\n",
    "    #   [0, 0, 1],\n",
    "    #   [0, 0, 0]]\n",
    "  look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n",
    "\n",
    "  padding_mask = create_padding_mask(x)\n",
    "\n",
    "  return tf.maximum(look_ahead_mask, padding_mask) # 내자신 이후도 보지 말고, 패딩도 보지 말라"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "93059061",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(create_look_ahead_mask(tf.constant([[1, 2, 3, 4, 5]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4c9c6c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(create_look_ahead_mask(tf.constant([[0, 5, 1, 5, 5]])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb9ded47",
   "metadata": {},
   "source": [
    "## 인코더"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a9a6f3",
   "metadata": {},
   "source": [
    "**인코더층**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ff8970dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인코더 하나의 레이어를 함수로 구현.\n",
    "# 이 하나의 레이어 안에는 두 개의 서브 레이어가 존재합니다.\n",
    "  # units : FFN의 내부 유닛 수\n",
    "  # d_model : 임베딩 차원\n",
    "  # num_heads : 멀티헤드 어센션의 헤드 개수\n",
    "def encoder_layer(units, d_model, num_heads, dropout, name=\"encoder_layer\"):\n",
    "  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
    "\n",
    "  # 패딩 마스크 사용\n",
    "  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    " # padding_mask.shape = (batch_size, 1, 1, seq_len_k)\n",
    " # attention_logits.shape = (batch_size, num_heads, seq_len_q, seq_len_k)\n",
    "\n",
    "  # 첫 번째 서브 레이어 : 멀티 헤드 어텐션 수행 (셀프 어텐션)\n",
    "  attention = MultiHeadAttention(\n",
    "      d_model, num_heads, name=\"attention\")({\n",
    "          'query': inputs,\n",
    "          'key': inputs,\n",
    "          'value': inputs,\n",
    "          'mask': padding_mask\n",
    "      })\n",
    "\n",
    "  # 어텐션의 결과는 Dropout과 Layer Normalization이라는 훈련을 돕는 테크닉을 수행\n",
    "  attention = tf.keras.layers.Dropout(rate=dropout)(attention)\n",
    "  attention = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(inputs + attention)\n",
    "\n",
    "  # 두 번째 서브 레이어 : 2개의 완전연결층\n",
    "  outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention)\n",
    "  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
    "\n",
    "  # 완전연결층의 결과는 Dropout과 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
    "  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "  outputs = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(attention + outputs)\n",
    "\n",
    "  return tf.keras.Model(\n",
    "      inputs=[inputs, padding_mask], outputs=outputs, name=name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9be61183",
   "metadata": {},
   "source": [
    "**인코더**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "06abce0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder(vocab_size,\n",
    "            num_layers,\n",
    "            units,\n",
    "            d_model,\n",
    "            num_heads,\n",
    "            dropout,\n",
    "            name=\"encoder\"):\n",
    "  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "\n",
    "  # 패딩 마스크 사용\n",
    "  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "  \n",
    "\n",
    "  # 임베딩 레이어\n",
    "  embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
    "  embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "\n",
    "  # 포지셔널 인코딩\n",
    "  # embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
    "  embeddings = PositionalEncoding(MAX_LENGTH, d_model)(embeddings)\n",
    "\n",
    "  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
    "\n",
    "  # num_layers만큼 쌓아올린 인코더의 층.\n",
    "  for i in range(num_layers):\n",
    "    outputs = encoder_layer(\n",
    "        units=units,\n",
    "        d_model=d_model,\n",
    "        num_heads=num_heads,\n",
    "        dropout=dropout,\n",
    "        name=\"encoder_layer_{}\".format(i),\n",
    "    )([outputs, padding_mask])\n",
    "\n",
    "  return tf.keras.Model(\n",
    "      inputs=[inputs, padding_mask], outputs=outputs, name=name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0baa2763",
   "metadata": {},
   "source": [
    "## 디코더"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d983a3",
   "metadata": {},
   "source": [
    "**디코더층**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "aab77f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 디코더 하나의 레이어를 함수로 구현.\n",
    "# 이 하나의 레이어 안에는 세 개의 서브 레이어가 존재합니다.\n",
    "  # units : FFN의 내부 유닛 수\n",
    "  # d_model : 임베딩 차원\n",
    "  # num_heads : 멀티헤드 어센션의 헤드 개수\n",
    "def decoder_layer(units, d_model, num_heads, dropout, name=\"decoder_layer\"):\n",
    "  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
    "  enc_outputs = tf.keras.Input(shape=(None, d_model), name=\"encoder_outputs\")\n",
    "    \n",
    "  look_ahead_mask = tf.keras.Input(\n",
    "      shape=(1, None, None), name=\"look_ahead_mask\")\n",
    "  # look_ahead_mask.shape = (batch_size, 1, seq_len_q, seq_len_k)\n",
    "  # batch_size는 Keras Input에서 None으로 자동 처리\n",
    "  # 1 → num_heads 차원에 broadcasting 가능\n",
    "  # 모든 헤드에 동일한 마스크를 적용하면서도 시퀀스 길이에 따라 다르게 작동\n",
    "  # shape=(1, None, None)은 멀티헤드 어텐션에 자연스럽게 마스크를 덧붙일 수 있게 하기 위한 브로드캐스트 설계\n",
    "\n",
    "  padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
    "  # padding_mask.shape = (batch_size, 1, 1, seq_len_k)\n",
    "  # 1 → num_heads 차원에 broadcasting 가능\n",
    "  # 1 → seq_len_q에 대해 모든 쿼리에 동일한 마스크 적용\n",
    "\n",
    "  # 첫 번째 서브 레이어 : 마스크드 멀티 헤드 어텐션 수행 (셀프 어텐션)\n",
    "  attention1 = MultiHeadAttention(\n",
    "      d_model, num_heads, name=\"attention_1\")(inputs={\n",
    "          'query': inputs,\n",
    "          'key': inputs,\n",
    "          'value': inputs,\n",
    "          'mask': look_ahead_mask\n",
    "      })\n",
    "\n",
    "  # 멀티 헤드 어텐션의 결과는 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
    "  attention1 = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(attention1 + inputs)\n",
    "\n",
    "  # 두 번째 서브 레이어 : 멀티 헤드 어텐션 수행 (인코더-디코더 어텐션)\n",
    "  attention2 = MultiHeadAttention(\n",
    "      d_model, num_heads, name=\"attention_2\")(inputs={\n",
    "          'query': attention1,\n",
    "          'key': enc_outputs,\n",
    "          'value': enc_outputs,\n",
    "          'mask': padding_mask\n",
    "      })\n",
    "\n",
    "  # 멀티 헤드 어텐션의 결과는\n",
    "  # Dropout과 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
    "  attention2 = tf.keras.layers.Dropout(rate=dropout)(attention2)\n",
    "  attention2 = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(attention2 + attention1)\n",
    "\n",
    "  # 세 번째 서브 레이어 : 2개의 완전연결층\n",
    "  outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention2)\n",
    "  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
    "\n",
    "  # 완전연결층의 결과는 Dropout과 LayerNormalization 수행\n",
    "  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "  outputs = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(outputs + attention2)\n",
    "\n",
    "  return tf.keras.Model(\n",
    "      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
    "      outputs=outputs,\n",
    "      name=name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed5633fe",
   "metadata": {},
   "source": [
    "**디코더**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "472dc063",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder(vocab_size,\n",
    "            num_layers,\n",
    "            units,\n",
    "            d_model,\n",
    "            num_heads,\n",
    "            dropout,\n",
    "            name='decoder'):\n",
    "  inputs = tf.keras.Input(shape=(None,), name='inputs')\n",
    "  enc_outputs = tf.keras.Input(shape=(None, d_model), name='encoder_outputs')\n",
    "  look_ahead_mask = tf.keras.Input(\n",
    "      shape=(1, None, None), name='look_ahead_mask')\n",
    "\n",
    "  # 패딩 마스크\n",
    "  padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
    "  \n",
    "  # 임베딩 레이어\n",
    "  embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
    "  # shape: (batch_size, seq_len, d_model)\n",
    "  embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "  # 스케일을 키운다 -> 벡터의 값을 약간 더 강하게 만들기 위한 정규화 효과 \n",
    "  # 1) 초기 어덴션 스코어가 너무 작아지지 않도록 : 임베딩 값이 작으면 → QKᵀ의 값도 작아짐 → Softmax가 평평해지고, 학습이 느려짐\n",
    "  # 2) 어텐션 연산에서 Q, K, V의 스케일과 맞춰주기 위함 : 어텐션에서는 QKᵀ / √d_k로 나누니까, 임베딩은 * √d_model로 곱해 균형을 맞춤\n",
    "\n",
    "  # 포지셔널 인코딩\n",
    "  # pos_embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
    "  pos_embeddings = PositionalEncoding(MAX_LENGTH, d_model)(embeddings)\n",
    "\n",
    "  # Dropout이라는 훈련을 돕는 테크닉을 수행\n",
    "  outputs = tf.keras.layers.Dropout(rate=dropout)(pos_embeddings)\n",
    "\n",
    "  for i in range(num_layers):\n",
    "    outputs = decoder_layer(\n",
    "        units=units,\n",
    "        d_model=d_model,\n",
    "        num_heads=num_heads,\n",
    "        dropout=dropout,\n",
    "        name='decoder_layer_{}'.format(i),\n",
    "    )(inputs=[outputs, enc_outputs, look_ahead_mask, padding_mask])\n",
    "\n",
    "  return tf.keras.Model(\n",
    "      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
    "      outputs=outputs,\n",
    "      name=name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b460a64",
   "metadata": {},
   "source": [
    "## 모델 정의 및 학습하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cfa17410",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformer(vocab_size,\n",
    "                num_layers,\n",
    "                units,\n",
    "                d_model,\n",
    "                num_heads,\n",
    "                dropout,\n",
    "                name=\"transformer\"):\n",
    "  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "  dec_inputs = tf.keras.Input(shape=(None,), name=\"dec_inputs\")\n",
    "\n",
    "  # 인코더에서 패딩을 위한 마스크\n",
    "  enc_padding_mask = tf.keras.layers.Lambda(\n",
    "      create_padding_mask, output_shape=(1, 1, None),\n",
    "      name='enc_padding_mask')(inputs)\n",
    "\n",
    "  # 디코더에서 미래의 토큰을 마스크 하기 위해서 사용합니다.\n",
    "  # 내부적으로 패딩 마스크도 포함되어져 있습니다.\n",
    "  look_ahead_mask = tf.keras.layers.Lambda(\n",
    "      create_look_ahead_mask,\n",
    "      output_shape=(1, None, None),\n",
    "      name='look_ahead_mask')(dec_inputs)\n",
    "\n",
    "  # 두 번째 어텐션 블록에서 인코더의 벡터들을 마스킹\n",
    "  # 디코더에서 패딩을 위한 마스크\n",
    "  dec_padding_mask = tf.keras.layers.Lambda(\n",
    "      create_padding_mask, output_shape=(1, 1, None),\n",
    "      name='dec_padding_mask')(inputs)\n",
    "\n",
    "  # 인코더\n",
    "  enc_outputs = encoder(\n",
    "      vocab_size=vocab_size,\n",
    "      num_layers=num_layers,\n",
    "      units=units,\n",
    "      d_model=d_model,\n",
    "      num_heads=num_heads,\n",
    "      dropout=dropout,\n",
    "  )(inputs=[inputs, enc_padding_mask])\n",
    "\n",
    "  # 디코더\n",
    "  dec_outputs = decoder(\n",
    "      vocab_size=vocab_size,\n",
    "      num_layers=num_layers,\n",
    "      units=units,\n",
    "      d_model=d_model,\n",
    "      num_heads=num_heads,\n",
    "      dropout=dropout,\n",
    "  )(inputs=[dec_inputs, enc_outputs, look_ahead_mask, dec_padding_mask])\n",
    "\n",
    "  # 완전연결층\n",
    "  outputs = tf.keras.layers.Dense(units=vocab_size, name=\"outputs\")(dec_outputs)\n",
    "\n",
    "  return tf.keras.Model(inputs=[inputs, dec_inputs], outputs=outputs, name=name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb658cea",
   "metadata": {},
   "source": [
    "**손실함수**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "aeaac3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#레이블인 시퀀스에 패딩이 되어 있으므로, loss를 계산할 때 패딩 마스크를 적용해야한다\n",
    "def loss_function(y_true, y_pred):\n",
    "  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1)) \n",
    "  # y_true : (batch_size, seq_len)\n",
    "  # -1 : 남은 차원은 알아서 계산\n",
    "  # seq : MAX_LENGTH - 1인 이유는 → 디코더의 정답 시퀀스는 보통 <start> 토큰 제거한 상태\n",
    "  \n",
    "  loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "      from_logits=True, reduction='none')(y_true, y_pred)\n",
    "    # from_logits=True: y_pred가 softmax 되기 전 값 (logits : softmax를 거치기 직전값)이기 때문\n",
    "    # → 손실 함수 내부에서 softmax를 자동으로 처리\n",
    "    # reduction='none': 손실을 일괄 평균하지 않고, 토큰마다 개별 손실 계산\n",
    "    # → 나중에 마스크를 씌워서 패딩 위치 손실은 제거할 수 있게 함\n",
    "\n",
    "  mask = tf.cast(tf.not_equal(y_true, 0), tf.float32)\n",
    "  loss = tf.multiply(loss, mask)\n",
    "    # y_true == 0인 위치는 패딩이므로 손실에서 제외. 그래서 0인 위치는 0, 나머지는 1인 마스크 생성\n",
    "\n",
    "  return tf.reduce_mean(loss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d43ffb2",
   "metadata": {},
   "source": [
    "**Custom Learning rate Scheduling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e1ea47d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 초기엔 학습률을 점점 올리고, 그 후엔 학습률을 점점 낮추는 방식\n",
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "\n",
    "  def __init__(self, d_model, warmup_steps=4000):\n",
    "    super(CustomSchedule, self).__init__()\n",
    "\n",
    "    self.d_model = d_model\n",
    "    self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "\n",
    "    self.warmup_steps = warmup_steps                    # warmup_steps: 학습률을 올리는 단계 수\n",
    "\n",
    "  def __call__(self, step):\n",
    "    arg1 = tf.math.rsqrt(step)\n",
    "    arg2 = step * (self.warmup_steps**-1.5)\n",
    "\n",
    "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "800a31aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Train Step')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample_learning_rate = CustomSchedule(d_model=128)\n",
    "\n",
    "plt.plot(sample_learning_rate(tf.range(200000, dtype=tf.float32)))\n",
    "plt.ylabel(\"Learning Rate\")\n",
    "plt.xlabel(\"Train Step\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851fe92c",
   "metadata": {},
   "source": [
    "**모델 컴파일**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "84b90a32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"transformer\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "inputs (InputLayer)             [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dec_inputs (InputLayer)         [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "enc_padding_mask (Lambda)       (None, 1, 1, None)   0           inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "encoder (Functional)            (None, None, 256)    5253376     inputs[0][0]                     \n",
      "                                                                 enc_padding_mask[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "look_ahead_mask (Lambda)        (None, 1, None, None 0           dec_inputs[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dec_padding_mask (Lambda)       (None, 1, 1, None)   0           inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "decoder (Functional)            (None, None, 256)    6835456     dec_inputs[0][0]                 \n",
      "                                                                 encoder[0][0]                    \n",
      "                                                                 look_ahead_mask[0][0]            \n",
      "                                                                 dec_padding_mask[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "outputs (Dense)                 (None, None, 8167)   2098919     decoder[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 14,187,751\n",
      "Trainable params: 14,187,751\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session() # TensorFlow에서 메모리 관리와 관련된 문제를 방지하기 위해 사용하는 함수\n",
    "                                 # Keras의 전역 상태(예: 모델, 레이어, 그래프 등)를 초기화해서 메모리를 정리\n",
    "\n",
    "# 하이퍼파라미터\n",
    "NUM_LAYERS = 6 # 인코더와 디코더의 층의 개수  ( 논문 6->2)\n",
    "D_MODEL = 256 # 인코더와 디코더 내부의 입, 출력의 고정 차원  (논문 512 -> 256)\n",
    "NUM_HEADS = 8 # 멀티 헤드 어텐션에서의 헤드 수 \n",
    "UNITS = 512 # 피드 포워드 신경망의 은닉층의 크기\n",
    "DROPOUT = 0.1 # 드롭아웃의 비율\n",
    "\n",
    "model = transformer(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    units=UNITS,\n",
    "    d_model=D_MODEL,\n",
    "    num_heads=NUM_HEADS,\n",
    "    dropout=DROPOUT)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b6fa2c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = CustomSchedule(D_MODEL)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(\n",
    "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
    "  return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e40528f",
   "metadata": {},
   "source": [
    "**모델 훈련**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f380fb97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='accuracy',     # 모니터링 대상\n",
    "    patience=3,             # 개선 없으면 몇 epoch 후에 멈출지\n",
    "    restore_best_weights=True,  # 가장 성능 좋았던 가중치를 복원할지 여부\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9d297c4a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "185/185 [==============================] - 22s 119ms/step - loss: 0.3293 - accuracy: 0.1133\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "185/185 [==============================] - 22s 121ms/step - loss: 0.3172 - accuracy: 0.1152\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/30\n",
      "185/185 [==============================] - 22s 118ms/step - loss: 0.2994 - accuracy: 0.1186\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/30\n",
      "185/185 [==============================] - 22s 117ms/step - loss: 0.2862 - accuracy: 0.1206\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/30\n",
      "185/185 [==============================] - 22s 118ms/step - loss: 0.2735 - accuracy: 0.1231\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/30\n",
      "185/185 [==============================] - 22s 118ms/step - loss: 0.2609 - accuracy: 0.1254\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/30\n",
      "185/185 [==============================] - 22s 117ms/step - loss: 0.2517 - accuracy: 0.1270\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/30\n",
      "185/185 [==============================] - 22s 117ms/step - loss: 0.2442 - accuracy: 0.1282\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/30\n",
      "185/185 [==============================] - 22s 117ms/step - loss: 0.2383 - accuracy: 0.1292\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/30\n",
      "185/185 [==============================] - 22s 117ms/step - loss: 0.2311 - accuracy: 0.1302\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/30\n",
      "185/185 [==============================] - 22s 117ms/step - loss: 0.2255 - accuracy: 0.1309\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/30\n",
      "185/185 [==============================] - 22s 117ms/step - loss: 0.2199 - accuracy: 0.1319\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/30\n",
      "185/185 [==============================] - 22s 117ms/step - loss: 0.2157 - accuracy: 0.1326\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/30\n",
      "185/185 [==============================] - 22s 118ms/step - loss: 0.2113 - accuracy: 0.1334\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/30\n",
      "185/185 [==============================] - 22s 118ms/step - loss: 0.2073 - accuracy: 0.1339\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/30\n",
      "185/185 [==============================] - 22s 118ms/step - loss: 0.2024 - accuracy: 0.1345\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/30\n",
      "185/185 [==============================] - 22s 118ms/step - loss: 0.1988 - accuracy: 0.1351\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/30\n",
      "185/185 [==============================] - 22s 118ms/step - loss: 0.1953 - accuracy: 0.1356\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/30\n",
      "185/185 [==============================] - 22s 118ms/step - loss: 0.1916 - accuracy: 0.1362\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/30\n",
      "185/185 [==============================] - 22s 117ms/step - loss: 0.1883 - accuracy: 0.1366\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/30\n",
      "185/185 [==============================] - 22s 118ms/step - loss: 0.1860 - accuracy: 0.1370\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/30\n",
      "185/185 [==============================] - 22s 118ms/step - loss: 0.1825 - accuracy: 0.1374\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/30\n",
      "185/185 [==============================] - 22s 117ms/step - loss: 0.1809 - accuracy: 0.1377\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/30\n",
      "185/185 [==============================] - 22s 118ms/step - loss: 0.1775 - accuracy: 0.1381\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/30\n",
      "185/185 [==============================] - 22s 118ms/step - loss: 0.1759 - accuracy: 0.1384\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/30\n",
      "185/185 [==============================] - 22s 117ms/step - loss: 0.1734 - accuracy: 0.1389\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/30\n",
      "185/185 [==============================] - 22s 117ms/step - loss: 0.1711 - accuracy: 0.1391\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/30\n",
      "185/185 [==============================] - 22s 117ms/step - loss: 0.1686 - accuracy: 0.1392\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/30\n",
      "185/185 [==============================] - 22s 118ms/step - loss: 0.1667 - accuracy: 0.1399\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/30\n",
      "185/185 [==============================] - 22s 117ms/step - loss: 0.1647 - accuracy: 0.1403\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 30\n",
    "history1 = model.fit(dataset, epochs=EPOCHS, verbose=1, callbacks = early_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f24e4b5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'accuracy'])\n"
     ]
    }
   ],
   "source": [
    "print(history1.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "3bc6972f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "acc = history1.history['accuracy']\n",
    "\n",
    "loss = history1.history['loss']\n",
    "\n",
    "\n",
    "epochs_range = range(1, len(acc) + 1)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(14, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "#plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "#plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e6dec49",
   "metadata": {},
   "source": [
    "## 테스트 (inerence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ddd17c",
   "metadata": {},
   "source": [
    "1) 새로운 입력 문장에 대해서는 훈련 때와 동일한 전처리를 거친다.\n",
    "2) 입력 문장을 토크나이징하고, START_TOKEN과 END_TOKEN을 추가한다.\n",
    "3) 패딩 마스킹과 룩 어헤드 마스킹을 계산한다.\n",
    "4) 디코더는 입력 시퀀스로부터 다음 단어를 예측한다.\n",
    "5) 디코더는 예측된 다음 단어를 기존의 입력 시퀀스에 추가하여 새로운 입력으로 사용한다.\n",
    "6) END_TOKEN이 예측되거나 문장의 최대 길이에 도달하면 디코더는 동작을 멈춘다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "6ce51321",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder_inference(sentence):\n",
    "  sentence = preprocess_sentence(sentence)\n",
    "\n",
    "  # 입력된 문장을 정수 인코딩 후, 시작 토큰과 종료 토큰을 앞뒤로 추가.\n",
    "  # ex) Where have you been? → [[8331   86   30    5 1059    7 8332]]\n",
    "  sentence = tf.expand_dims(\n",
    "      START_TOKEN + tokenizer.encode(sentence) + END_TOKEN, axis=0)\n",
    "     # expand_dims : shape을 (1, sequence_length)로 만들어 배치처럼 보이게\n",
    "\n",
    "  # 디코더의 현재까지의 예측한 출력 시퀀스가 지속적으로 저장되는 변수.\n",
    "  # 처음에는 예측한 내용이 없음으로 시작 토큰만 별도 저장. ex) 8331\n",
    "  output_sequence = tf.expand_dims(START_TOKEN, 0)\n",
    "\n",
    "  # 디코더의 인퍼런스 단계\n",
    "  for i in range(MAX_LENGTH):\n",
    "    # 디코더는 최대 MAX_LENGTH의 길이만큼 다음 단어 예측을 반복합니다.\n",
    "    predictions = model(inputs=[sentence, output_sequence], training=False)\n",
    "    predictions = predictions[:, -1:, :]\n",
    "    \n",
    "    # predictions : (batch_size, sequence_length, vocab_size) -> shape : (1, 1, 8333)\n",
    "    # : : 배치 전체 (1)\n",
    "    # -1:은 가장 마지막 토큰의 예측만 가져오기\n",
    "    # : : 전체 vocab에 대한 확률 (8333)\n",
    "    \n",
    "\n",
    "    # 현재 예측한 단어의 정수\n",
    "    predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)    # -> shape : (1,1)\n",
    "    #  tf.argmax는 int64 자료형 (자료형의 기본은 int64)\n",
    "    # output_sequece는 int32 자료형 (대부분 TesorFlow 모델은 int32로 처리)\n",
    "\n",
    "    # 만약 현재 예측한 단어가 종료 토큰이라면 for문을 종료\n",
    "    if tf.equal(predicted_id, END_TOKEN[0]):\n",
    "      break\n",
    "\n",
    "    # 예측한 단어들은 지속적으로 output_sequence에 추가됩니다.\n",
    "    # 이 output_sequence는 다시 디코더의 입력이 됩니다.\n",
    "    output_sequence = tf.concat([output_sequence, predicted_id], axis=-1)\n",
    "\n",
    "  return tf.squeeze(output_sequence, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "fff3f72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_generation(sentence):\n",
    "  # 입력 문장에 대해서 디코더를 동작 시켜 예측된 정수 시퀀스를 리턴받습니다.\n",
    "  prediction = decoder_inference(sentence)\n",
    "\n",
    "  # 정수 시퀀스를 다시 텍스트 시퀀스로 변환합니다.\n",
    "  predicted_sentence = tokenizer.decode(\n",
    "      [i for i in prediction if i < tokenizer.vocab_size])\n",
    "\n",
    "  print('입력 : {}'.format(sentence))\n",
    "  print('출력 : {}'.format(predicted_sentence))\n",
    "\n",
    "  return predicted_sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "4d3f11a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 요즘 머리가 아프고 피곤해 어떻게 하면 좋을까?\n",
      "출력 : 다시 연락하고 싶다면 전화해보세요 . \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'다시 연락하고 싶다면 전화해보세요 . '"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('요즘 머리가 아프고 피곤해 어떻게 하면 좋을까?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "22fcb51f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : test는 어땠어?\n",
      "출력 : 너무 신경쓰지마세요 . \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'너무 신경쓰지마세요 . '"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation(\"test는 어땠어?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f90c321d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 내일 비가 올거 같아?\n",
      "출력 : 그래서 배우는 게 즐겁죠 . \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'그래서 배우는 게 즐겁죠 . '"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation(\"내일 비가 올거 같아?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "00e22078",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 내일 뭐 하고 싶어?\n",
      "출력 : 제철과일이 정말 좋아요 . \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'제철과일이 정말 좋아요 . '"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation(\"내일 뭐 하고 싶어?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "8e4398ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 딥러닝으로 이미지 생성 할 수 있어\n",
      "출력 : 혼자도 함께도 잘 지내는 게 좋죠 . \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'혼자도 함께도 잘 지내는 게 좋죠 . '"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation(\"딥러닝으로 이미지 생성 할 수 있어\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c1ef9dec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 어깨 운동 추천해줄래?\n",
      "출력 : 발전적인 관계가 아니라면 정리가 필요한 시기네요 . \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'발전적인 관계가 아니라면 정리가 필요한 시기네요 . '"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation(\"어깨 운동 추천해줄래?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d981375c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : what are you doing?\n",
      "출력 : 꼭 해야 하는 건 없어요 . \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'꼭 해야 하는 건 없어요 . '"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation(\"what are you doing?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "8ab3338f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 호두 정과 정말 맛있어\n",
      "출력 : 한푼 두푼 차곡\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'한푼 두푼 차곡'"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation(\"호두 정과 정말 맛있어\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "1f334637",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 흑임자 두부 만드는 법 알아\n",
      "출력 : 직접적이든 간접적이든 의사를 확실히 밝혀보세요 . \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'직접적이든 간접적이든 의사를 확실히 밝혀보세요 . '"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation(\"흑임자 두부 만드는 법 알아\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba303719",
   "metadata": {},
   "source": [
    "## 회고 \n",
    "\n",
    "질문에 대한 답변이 적절하지는 않지만, 짧은 문장으로 부드럽게 응답한다. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
