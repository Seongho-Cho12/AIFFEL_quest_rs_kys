{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c1e2be7",
   "metadata": {},
   "source": [
    "## Transformer와 비교해 변경이 필요한 부분 \n",
    "\n",
    "\n",
    "1. 데이타 전처리 \n",
    "   - A안.  Input은 Question과 Answer를 붙인다. \n",
    "   - B안.  Input/ouput은 START와 END_TOKEN을 붙인다\n",
    "\n",
    "2. Positional Embedding\n",
    "   - Embedding Layer를 추가한다. \n",
    "   - 단어 임베딩과 별도로 inputs에 대한 positional embeding을 추가한다. \n",
    "   \n",
    "3. Encoder \n",
    "   - Encoder는 삭제한다. \n",
    "   \n",
    "4. Decorder 층\n",
    "  - Decoder층은 Encoder가 없으므로, Encoder-Decoder Mutlti-head Attention Layer가 없음\n",
    "    따라서 padding_mask도 필요 없음\n",
    "  - Decoder 층 \n",
    "      - Masked Multi-head Attention 층\n",
    "      - Layer Norm\n",
    "      - Feed Forward \n",
    "      - Layer Norm\n",
    "\n",
    "5. 모델 구성 \n",
    "  - gtp 모델은 [inputs, look_ahead_mask]와 [outputs]로 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63dd0bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ffc395",
   "metadata": {},
   "source": [
    "## 데이타 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8fe4a59a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Q            A  label\n",
      "0           12시 땡!   하루가 또 가네요.      0\n",
      "1      1지망 학교 떨어졌어    위로해 드립니다.      0\n",
      "2     3박4일 놀러가고 싶다  여행은 언제나 좋죠.      0\n",
      "3  3박4일 정도 놀러가고 싶다  여행은 언제나 좋죠.      0\n",
      "4          PPL 심하네   눈살이 찌푸려지죠.      0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# CSV 로딩\n",
    "data_path = os.path.join(os.getenv(\"HOME\"), \"aiffel/transformer_chatbot/data/ChatbotData .csv\")\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d25a8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전처리 함수\n",
    "def preprocess_sentence(sentence):\n",
    "\n",
    "  # 소문자화 & 공백 제거 (한국어는 대소문자 의미 없음, 하지만 영어 혼합 대비)\n",
    "  sentence = sentence.lower().strip()\n",
    "\n",
    "  # 단어와 구두점(punctuation) 사이의 거리를 만듭니다.\n",
    "  # 예를 들어서 \"I am a student.\" => \"I am a student .\"와 같이\n",
    "  # student와 온점 사이에 거리를 만듭니다.\n",
    "  sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)  # 구두점 앞뒤로 공백추가\n",
    " \n",
    "  # 허용된 문자 외 제거 (한글, 영어, 숫자, 구두점)\n",
    "  sentence = re.sub(r\"[^가-힣ㄱ-ㅎㅏ-ㅣa-zA-Z0-9?.!,]+\", \" \", sentence)\n",
    "  \n",
    "  # 다중 공백 정리\n",
    "  sentence = re.sub(r'[\" \"]+', \" \", sentence)        # 여러개의 공백을 하나로\n",
    "  \n",
    "  return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11fb2808",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플 수 : 11823\n",
      "전체 샘플 수 : 11823\n",
      "전처리 후의 질문: ['12시 땡 ! ', '1지망 학교 떨어졌어', '3박4일 놀러가고 싶다', '3박4일 정도 놀러가고 싶다', 'ppl 심하네']\n",
      "전처리 후의 답변: ['하루가 또 가네요 . ', '위로해 드립니다 . ', '여행은 언제나 좋죠 . ', '여행은 언제나 좋죠 . ', '눈살이 찌푸려지죠 . ']\n"
     ]
    }
   ],
   "source": [
    "# 질문과 답변 분리 + 전처리 적용\n",
    "questions = [preprocess_sentence(q) for q in df['Q']]\n",
    "answers = [preprocess_sentence(a) for a in df['A']]\n",
    "\n",
    "print('전체 샘플 수 :', len(questions))\n",
    "print('전체 샘플 수 :', len(answers))\n",
    "\n",
    "print(\"전처리 후의 질문:\", questions[:5])\n",
    "print(\"전처리 후의 답변:\", answers[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "921e0b7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 길이 확인을 위한 리스트 생성\n",
    "question_lengths = [len(q) for q in questions]\n",
    "answer_lengths = [len(a) for a in answers]\n",
    "\n",
    "# 히스토그램 시각화\n",
    "plt.hist(question_lengths, bins=50, alpha=0.6, label='Questions')\n",
    "plt.hist(answer_lengths, bins=50, alpha=0.6, label='Answers')\n",
    "plt.xlabel('Length')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Token Length Distribution')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c5e99a7",
   "metadata": {},
   "source": [
    "**Subword Tokenizer**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df3d3846",
   "metadata": {},
   "source": [
    "1) TensorFlow Datasets SubwordTextEncoder 를 토크나이저로 사용한다.  \n",
    "    단어보다 더 작은 단위인 Subword를 기준으로 토크나이징하고,  각 토큰을 고유한 정수로 인코딩 한다.\n",
    "\n",
    "2) 각 문장을 토큰화하고 각 문장의 시작과 끝을 나타내는 START_TOKEN 및 END_TOKEN을 추가한다.\n",
    "\n",
    "3) 최대 길이 MAX_LENGTH 인 MAX_LENGTH을 넘는 문장들은 필터링한다.\n",
    "\n",
    "4) MAX_LENGTH보다 길이가 짧은 문장들은 MAX_LENGTH에 맞도록 패딩 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d99ccec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "\n",
    "\n",
    "# 질문과 답변 데이터셋에 대해서 Vocabulary 생성\n",
    "# 인자 : corpus = 문자열 리스트, target_vocab_size = 원하는 어휘 수\n",
    "tokenizer = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(questions + answers, target_vocab_size=2**13)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ef9f8bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START_TOKEN의 번호 : [8168]\n",
      "END_TOKEN의 번호 : [8169]\n",
      "DEL_TOKEN의 번호 : [8170]\n",
      "단어장의 크기 : 8171\n"
     ]
    }
   ],
   "source": [
    "# 시작 토큰과 종료 토큰에 고유한 정수를 부여합니다.\n",
    "START_TOKEN, END_TOKEN = [tokenizer.vocab_size], [tokenizer.vocab_size + 1]\n",
    "DEL_TOKEN = [tokenizer.vocab_size + 2]\n",
    "\n",
    "print('START_TOKEN의 번호 :' ,[tokenizer.vocab_size])\n",
    "print('END_TOKEN의 번호 :' ,[tokenizer.vocab_size + 1])\n",
    "print('DEL_TOKEN의 번호 :' ,[tokenizer.vocab_size + 2])\n",
    "\n",
    "# 시작 토큰과 종료 토큰을 고려하여 +3를 하여 단어장의 크기를 산정합니다.\n",
    "VOCAB_SIZE = tokenizer.vocab_size + 3\n",
    "print('단어장의 크기 :',(VOCAB_SIZE))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d6cf30a",
   "metadata": {},
   "source": [
    "**INPUT 및 LABEL 정의**\n",
    "\n",
    "  - input은 질문과 대답으로 한 문장으로 계산  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f23745c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정수 인코딩, 최대 길이를 초과하는 샘플 제거, 패딩\n",
    "def tokenize_full_input(inputs, outputs):\n",
    "  tokenized_inputs, tokenized_outputs = [], []\n",
    "  \n",
    "  for (sentence1, sentence2) in zip(inputs, outputs):\n",
    "    \n",
    "    # 정수 인코딩 과정에서 시작 토큰과 종료 토큰을 추가\n",
    "    input_ids = START_TOKEN + tokenizer.encode(sentence1) + DEL_TOKEN\n",
    "    output_ids = tokenizer.encode(sentence2)+ END_TOKEN\n",
    "    \n",
    "    # 전체 input = 질문 + 대답\n",
    "    full_input = input_ids + output_ids \n",
    "    \n",
    "    # label은 padding 등을 고려해 필요 부분만 마스킹하도록 구성 (보통 output_ids에 해당)\n",
    "    labels = [-100] * len(input_ids) + output_ids  # input 부분은 loss 계산에서 제외\n",
    "\n",
    "    tokenized_inputs.append(full_input)\n",
    "    tokenized_outputs.append(labels)\n",
    "\n",
    "  return tokenized_inputs, tokenized_outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0248d4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정수 인코딩, 최대 길이를 초과하는 샘플 제거, 패딩\n",
    "def tokenize(inputs, outputs):\n",
    "  tokenized_inputs, tokenized_outputs = [], []\n",
    "  \n",
    "  for (sentence1, sentence2) in zip(inputs, outputs):\n",
    "    \n",
    "    # 정수 인코딩 과정에서 시작 토큰과 종료 토큰을 추가\n",
    "    input_ids = START_TOKEN + tokenizer.encode(sentence1) + END_TOKEN\n",
    "    output_ids = START_TOKEN+ tokenizer.encode(sentence2)+ END_TOKEN\n",
    "\n",
    "    tokenized_inputs.append(input_ids)\n",
    "    tokenized_outputs.append(output_ids)\n",
    "\n",
    "  return tokenized_inputs, tokenized_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7a475df7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 실제 질문과 답변 토큰화 수행\n",
    "tokenized_questions, tokenized_answers = tokenize(questions, answers)\n",
    "\n",
    "\n",
    "# 길이 확인을 위한 리스트 생성\n",
    "question_lengths = [len(q) for q in tokenized_questions]\n",
    "answer_lengths = [len(a) for a in tokenized_answers]\n",
    "\n",
    "# 히스토그램 시각화\n",
    "plt.hist(question_lengths, bins=50, alpha=0.6, label='Questions')\n",
    "plt.hist(answer_lengths, bins=50, alpha=0.6, label='Answers')\n",
    "plt.xlabel('Length')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Token Length Distribution')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bbb23396",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "질문 최대 길이: 23\n",
      "답변 최대 길이: 31\n",
      "98% 질문 길이: 14.0\n",
      "98% 답변 길이: 15.0\n"
     ]
    }
   ],
   "source": [
    "# 질문과 답변의 최대 길이 출력\n",
    "print('질문 최대 길이:', np.max(question_lengths))\n",
    "print('답변 최대 길이:', np.max(answer_lengths))\n",
    "\n",
    "# 98% 백분위수 기준 길이 출력\n",
    "print('98% 질문 길이:', np.percentile(question_lengths, 98))\n",
    "print('98% 답변 길이:', np.percentile(answer_lengths, 98))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4296a514",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 샘플의 최대 허용 길이 또는 패딩 후의 최종 길이\n",
    "MAX_LENGTH = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a532be57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_and_padding(tokenized_questions, tokenized_answers):\n",
    "\n",
    "    filtered_inputs, filtered_outputs = [], []\n",
    "\n",
    "    for q, a in zip(tokenized_questions, tokenized_answers):\n",
    "        if len(q) <= MAX_LENGTH and len(a) <= MAX_LENGTH:\n",
    "            filtered_inputs.append(q)\n",
    "            filtered_outputs.append(a)\n",
    "\n",
    "    # 패딩 적용\n",
    "    padded_inputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "        filtered_inputs, maxlen=MAX_LENGTH, padding='post'\n",
    "    )\n",
    "    padded_outputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "        filtered_outputs, maxlen=MAX_LENGTH, padding='post'\n",
    "    )\n",
    "\n",
    "    return padded_inputs, padded_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b55272bf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "필터링 후의 질문 샘플 개수: 11822\n",
      "필터링 후의 답변 샘플 개수: 11822\n"
     ]
    }
   ],
   "source": [
    "questions, answers = filter_and_padding(tokenized_questions, tokenized_answers)\n",
    "print('필터링 후의 질문 샘플 개수: {}'.format(len(questions)))\n",
    "print('필터링 후의 답변 샘플 개수: {}'.format(len(answers)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35277d4b",
   "metadata": {},
   "source": [
    "**교사 강요(Teacher Forcing)는 사용하지 않는다**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5cc1913d",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = 20000\n",
    "\n",
    "# 디코더는 이전의 target을 다음의 input으로 사용합니다.\n",
    "# 이에 따라 outputs에서는 START_TOKEN을 제거하겠습니다.\n",
    "dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    {\n",
    "        'inputs': questions,\n",
    "        \n",
    "        \n",
    "    },\n",
    "    {\n",
    "        'outputs': answers,      # 디코더 출력 (정답), START_TOKEN 제거\n",
    "    },\n",
    "))\n",
    "\n",
    "dataset = dataset.cache()                       # 메모리에 캐싱, 에포크가 반복될때 디스크 읽기/파싱 비용을 줄임\n",
    "dataset = dataset.shuffle(BUFFER_SIZE)          # 무작위로 섞지 않으면, 학습이 데이터 순서에 의존하게 되어 과적합 위험이 높아짐\n",
    "dataset = dataset.batch(BATCH_SIZE)             # 배치로 묶어서 모델에 한번에 전달\n",
    "dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE) # GPU가 학습하는 동안 CPU가 다음 배치를 미리 준비\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ad2e9a",
   "metadata": {},
   "source": [
    "## 공통 함수"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "854a749b",
   "metadata": {},
   "source": [
    "**포지셔널 임베딩**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5218d44d",
   "metadata": {},
   "source": [
    "- PositinalEncoding은 사인,코사인이 교차되도록 포지션을 계산하지만 \n",
    "- PositionalEmbedding은 Embedding Layer를 추가한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9265c62d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "\n",
    "# 포지셔널 임베딩 레이어\n",
    "# d_model : 임베딩 벡터의 차원,  각 단어 벡터의 차원 (예: 512)\n",
    "# position: 입력 문장에서의 임베딩 벡터의 위치, 시퀀스의 최대 길이 \n",
    "class PositionalEmbedding(tf.keras.layers.Layer):\n",
    "\n",
    "  def __init__(self, max_seq_len, embedding_dim):                                                           \n",
    "    super(PositionalEmbedding, self).__init__()\n",
    "    self.max_seq_len = max_seq_len\n",
    "    self.embedding_dim = embedding_dim\n",
    "    self.pos_embedding = tf.keras.layers.Embedding(\n",
    "                        input_dim = max_seq_len,\n",
    "                        output_dim = embedding_dim)\n",
    "    \n",
    "  def call(self, inputs):\n",
    "    # inputs : (batch_size, seq_len, d_model)\n",
    "    # self.pos_encoding : (1, max_position, d_model)\n",
    "    # inputs의 seq_len <= max_position\n",
    "    \n",
    "    seq_len = tf.shape(inputs)[1]\n",
    "    positions = tf.range(start=0, limit=seq_len, delta=1)\n",
    "    positions = tf.expand_dims(positions, 0)  # [1, seq_len]\n",
    "    positions = tf.tile(positions, [tf.shape(inputs)[0], 1])  # [batch_size, seq_len]\n",
    "    return self.pos_embedding(positions)  # [batch_size, seq_len, embedding_dim]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "499dbcde",
   "metadata": {},
   "source": [
    "**어텐션**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a243e20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 스케일드 닷 프로덕트 어텐션 함수\n",
    "def scaled_dot_product_attention(query, key, value, mask):\n",
    "  # 어텐션 가중치는 Q와 K의 닷 프로덕트\n",
    "\n",
    "  matmul_qk = tf.matmul(query, key, transpose_b=True)  # 행렬 곱셈(matrix multiplication), key를 transpose함\n",
    "  # Q: (batch_size, num_heads, seq_len_q, depth)\n",
    "  # K: (batch_size, num_heads, seq_len_k, depth)\n",
    "  # transpose : 마지막 2개 차원에 바뀜 \n",
    "  # K^T : (batch_size, num_heads, depth, seq_len_k)\n",
    "  # QK^T → shape: (batch_size, num_heads, seq_len_q, seq_len_k)\n",
    "\n",
    "  # 가중치를 정규화\n",
    "  # Q,K이 차원이 depth이고, depth가 커질수록 내적값도 커지므로, depth를 사용해서 scale을 줄여준다. \n",
    "  depth = tf.cast(tf.shape(key)[-1], tf.float32)       # key 마지막 차원의 크기를 float32로 변환 (부동소수점자료형)\n",
    "  logits = matmul_qk / tf.math.sqrt(depth)             # 차원수로 scaling하는 작업\n",
    "\n",
    "  # 패딩에 마스크 추가\n",
    "  # 마스크된 곳에는 아주 큰 마이너스 값으로 변경하여, 사용되지 않게.\n",
    "  if mask is not None:\n",
    "    logits += (mask * -1e9)\n",
    "\n",
    "  # softmax적용\n",
    "  attention_weights = tf.nn.softmax(logits, axis=-1)\n",
    "    \n",
    "  \n",
    "\n",
    "  # 최종 어텐션은 가중치와 V의 닷 프로덕트\n",
    "  output = tf.matmul(attention_weights, value)\n",
    "  # (seq_len_q, seq_len_k) @ (seq_len_k, depth) → (seq_len_q, depth)\n",
    "  # attention_logits  :  (batch_size, num_heads, seq_len_q, seq_len_k)\n",
    "  # V                 :  (batch_size, num_heads, seq_len_k, depth)\n",
    "  # output            :  (batch_size, num_heads, seq_len_q, depth)\n",
    "  return output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e89c1490",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "\n",
    "  def __init__(self, d_model, num_heads, name=\"multi_head_attention\"):\n",
    "    super(MultiHeadAttention, self).__init__(name=name)\n",
    "    self.num_heads = num_heads\n",
    "    self.d_model = d_model\n",
    "\n",
    "    assert d_model % self.num_heads == 0\n",
    "\n",
    "    self.depth = d_model // self.num_heads\n",
    "\n",
    "    self.query_dense = tf.keras.layers.Dense(units=d_model)\n",
    "    self.key_dense = tf.keras.layers.Dense(units=d_model)\n",
    "    self.value_dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "    self.dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "  def split_heads(self, inputs, batch_size):\n",
    "    # d_model -> num_heads * depth \n",
    "    inputs = tf.reshape(\n",
    "        inputs, shape=(batch_size, -1, self.num_heads, self.depth)) # -1: 자동으로 그 크기를 맞춰라 (seq_len)\n",
    "    return tf.transpose(inputs, perm=[0, 2, 1, 3])                  # (batch_size, num_heads, seq_len, depth)\n",
    "\n",
    "  def call(self, inputs):\n",
    "    query, key, value, mask = inputs['query'], inputs['key'], inputs[\n",
    "        'value'], inputs['mask']\n",
    "    \n",
    "    # inputs.shape = [batch_size, seq_len, embedding_dim]\n",
    "    batch_size = tf.shape(query)[0]\n",
    "\n",
    "    # Q, K, V에 각각 Dense를 적용합니다\n",
    "    # (batch_size, seq_len, embedding_dim)\n",
    "    query = self.query_dense(query)\n",
    "    key = self.key_dense(key)\n",
    "    value = self.value_dense(value)\n",
    "\n",
    "    # 병렬 연산을 위한 머리를 여러 개 만듭니다\n",
    "    # (batch_size, num_heads, seq_len, projection_dim(depth))\n",
    "    query = self.split_heads(query, batch_size)\n",
    "    key = self.split_heads(key, batch_size)\n",
    "    value = self.split_heads(value, batch_size)\n",
    "\n",
    "    # 스케일드 닷 프로덕트 어텐션 함수\n",
    "    scaled_attention = scaled_dot_product_attention(query, key, value, mask)\n",
    "    # shape : (batch_size, num_heads, seq_len_q, projection_dim)\n",
    "    scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
    "    # concat을 하려고 shape를 바꿈 : (batch_size, seq_len_q, num_heads, projection_dim(depth))\n",
    "\n",
    "    # 어텐션 연산 후에 각 결과를 다시 연결(concatenate)합니다 (num_heads * depth -> d_model)\n",
    "    # (batch_size, seq_len, embedding_dim)\n",
    "    concat_attention = tf.reshape(scaled_attention,\n",
    "                                  (batch_size, -1, self.d_model))\n",
    "\n",
    "    # 최종 결과에도 Dense를 한 번 더 적용합니다\n",
    "    outputs = self.dense(concat_attention)\n",
    "\n",
    "    return outputs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4682f60a",
   "metadata": {},
   "source": [
    "**패딩 마스크**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "51513b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "#모델이 의미 없는 패딩 토큰에 주의를 빼앗기지 않도록 하기 위해 **마스킹(masking)**을 한다.\n",
    "def create_padding_mask(x):\n",
    "  mask = tf.cast(tf.math.equal(x, 0), tf.float32)   # [7, 6, 0, 0, 0] → [False, False, True, True, True]\n",
    "                                                    # Boolen 값을 float32로 변경 → [0.0, 0.0, 1.0, 1.0, 1.0]\n",
    "  # (batch_size, 1, 1, sequence length_k)\n",
    "  return mask[:, tf.newaxis, tf.newaxis, :]         # 차원을 확장해서, 어덴션 스코어와 잘 계산되게 맞추어줌"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b6a875b",
   "metadata": {},
   "source": [
    "**룩 어헤드 마스킹(Look-ahead masking, 다음 단어 가리기)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "382ca56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_look_ahead_mask(x):\n",
    "  # (batch_size, seq_len, dim)\n",
    "  seq_len = tf.shape(x)[1]\n",
    "  \n",
    "  # tf.ones((seq_len, seq_len)) : (seq_len, seq_len)인 모든 원소가 1인 텐서\n",
    "    #  [[1, 1, 1],\n",
    "    #   [1, 1, 1],\n",
    "    #   [1, 1, 1]]\n",
    "  # tf.linalg.band_part ( input, num_lower, num_upper) : 행렬의 밴드부분만 남기고 나머지는 0으로 \n",
    "  # 하삼각 행렬(lower triangular matrix)을 생성\n",
    "    #  [[1, 0, 0],\n",
    "    #   [1, 1, 0],\n",
    "    #   [1, 1, 1]]\n",
    "  # mask = 1 - 하삼각 행렬  (자신보다 뒤에 있는 토큰에 1을 설정하는 마스크 )\n",
    "    #  [[0, 1, 1],\n",
    "    #   [0, 0, 1],\n",
    "    #   [0, 0, 0]]\n",
    "  look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n",
    " \n",
    "    \n",
    "  padding_mask = create_padding_mask(x)\n",
    "  # (batch_size, 1, 1, sequence length_k)\n",
    "\n",
    "  return tf.maximum(look_ahead_mask, padding_mask) # 내자신 이후도 보지 말고, 패딩도 보지 말라\n",
    "  # tf.maximum (a, b) : a, b는 같은 shape이거나, 브로드캐스트가 가능한 shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "754baae4",
   "metadata": {},
   "source": [
    "## 디코더"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fbfd043",
   "metadata": {},
   "source": [
    "**디코더층**\n",
    "\n",
    "  - Masked Multi-head Attention 층\n",
    "  - Layer Norm\n",
    "  - Feed Forward \n",
    "  - Layer Norm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1645938c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 디코더 하나의 레이어를 함수로 구현.\n",
    "# 이 하나의 레이어 안에는 세 개의 서브 레이어가 존재합니다.\n",
    "  # units : FFN의 내부 유닛 수\n",
    "  # d_model : 임베딩 차원\n",
    "  # num_heads : 멀티헤드 어센션의 헤드 개수\n",
    "def decoder_layer(units, d_model, num_heads, dropout, name=\"decoder_layer\"):\n",
    "  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")    \n",
    "  look_ahead_mask = tf.keras.Input(\n",
    "      shape=(1, None, None), name=\"look_ahead_mask\")\n",
    "  # look_ahead_mask.shape = (batch_size, 1, seq_len_q, seq_len_k)\n",
    "  # batch_size는 Keras Input에서 None으로 자동 처리\n",
    "  # 1 → num_heads 차원에 broadcasting 가능\n",
    "  # 모든 헤드에 동일한 마스크를 적용하면서도 시퀀스 길이에 따라 다르게 작동\n",
    "  # shape=(1, None, None)은 멀티헤드 어텐션에 자연스럽게 마스크를 덧붙일 수 있게 하기 위한 브로드캐스트 설계\n",
    "\n",
    "\n",
    "  # 1. 마스크드 멀티 헤드 어텐션 수행 (셀프 어텐션)\n",
    "  attention = MultiHeadAttention(\n",
    "      d_model, num_heads, name=\"attention\")(inputs={\n",
    "          'query': inputs,\n",
    "          'key': inputs,\n",
    "          'value': inputs,\n",
    "          'mask': look_ahead_mask\n",
    "      })\n",
    "\n",
    "  # 2. LayerNormalization\n",
    "  normal = tf.keras.layers.LayerNormalization(epsilon=1e-6)(attention + inputs)\n",
    "\n",
    "  # 3 : 2개의 완전연결층\n",
    "  outputs = tf.keras.layers.Dense(units=units, activation='relu')(normal)\n",
    "  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
    "\n",
    "  # 4. 완전연결층의 결과는 Dropout과 LayerNormalization 수행\n",
    "  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "  outputs = tf.keras.layers.LayerNormalization(epsilon=1e-6)(outputs + normal)\n",
    "\n",
    "\n",
    "  return tf.keras.Model(\n",
    "      inputs=[inputs, look_ahead_mask],\n",
    "      outputs=outputs,\n",
    "      name=name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6bab877",
   "metadata": {},
   "source": [
    "**디코더**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a9641342",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder(vocab_size,\n",
    "            num_layers,\n",
    "            units,\n",
    "            d_model,\n",
    "            num_heads,\n",
    "            dropout,\n",
    "            name='decoder'):\n",
    "  inputs = tf.keras.Input(shape=(None,), name='inputs')\n",
    "  \n",
    "  look_ahead_mask = tf.keras.Input(\n",
    "      shape=(1, None, None), name='look_ahead_mask')\n",
    "\n",
    "  # 임베딩 레이어\n",
    "  embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
    "  embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "  # 스케일을 키운다 -> 벡터의 값을 약간 더 강하게 만들기 위한 정규화 효과 \n",
    "  # 1) 초기 어덴션 스코어가 너무 작아지지 않도록 : 임베딩 값이 작으면 → QKᵀ의 값도 작아짐 → Softmax가 평평해지고, 학습이 느려짐\n",
    "  # 2) 어텐션 연산에서 Q, K, V의 스케일과 맞춰주기 위함 : 어텐션에서는 QKᵀ / √d_k로 나누니까, 임베딩은 * √d_model로 곱해 균형을 맞춤\n",
    "    \n",
    "  # 포지셔널 임베딩\n",
    "  pos_embeddings = PositionalEmbedding(MAX_LENGTH, d_model)(inputs)\n",
    "\n",
    "  embeddings += pos_embeddings\n",
    "\n",
    "  # Dropout이라는 훈련을 돕는 테크닉을 수행\n",
    "  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
    "\n",
    "  for i in range(num_layers):\n",
    "    outputs = decoder_layer(\n",
    "        units=units,\n",
    "        d_model=d_model,\n",
    "        num_heads=num_heads,\n",
    "        dropout=dropout,\n",
    "        name='decoder_layer_{}'.format(i),\n",
    "    )(inputs=[outputs, look_ahead_mask])\n",
    "\n",
    "  #outputs = tf.keras.layers.Dense(vocab_size, activation='softmax', name='outputs')(outputs)\n",
    "\n",
    "  return tf.keras.Model(\n",
    "      inputs=[inputs, look_ahead_mask],\n",
    "      outputs=outputs,\n",
    "      name=name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdf1bf96",
   "metadata": {},
   "source": [
    "**Custom Learning rate Scheduling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fb10b0b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 초기엔 학습률을 점점 올리고, 그 후엔 학습률을 점점 낮추는 방식\n",
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "\n",
    "  def __init__(self, d_model, warmup_steps=100):\n",
    "    super(CustomSchedule, self).__init__()\n",
    "\n",
    "    self.d_model = d_model\n",
    "    self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "\n",
    "    self.warmup_steps = warmup_steps                    # warmup_steps: 학습률을 올리는 단계 수\n",
    "\n",
    "  def __call__(self, step):\n",
    "    arg1 = tf.math.rsqrt(step)\n",
    "    arg2 = step * (self.warmup_steps**-1.5)\n",
    "\n",
    "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1a3ed912",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Train Step')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample_learning_rate = CustomSchedule(d_model=128)\n",
    "\n",
    "plt.plot(sample_learning_rate(tf.range(200000, dtype=tf.float32)))\n",
    "plt.ylabel(\"Learning Rate\")\n",
    "plt.xlabel(\"Train Step\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a53c82b",
   "metadata": {},
   "source": [
    "## 모델 정의 및 학습하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "689e202f",
   "metadata": {},
   "source": [
    "- decoder의 inputs과 outputs로 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "362f1ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gpt(vocab_size,\n",
    "                num_layers,\n",
    "                units,\n",
    "                d_model,\n",
    "                num_heads,\n",
    "                dropout,\n",
    "                name=\"gpt\"):\n",
    "  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "  #dec_inputs = tf.keras.Input(shape=(None,), name=\"dec_inputs\")\n",
    "\n",
    "  # 디코더에서 미래의 토큰을 마스크 하기 위해서 사용합니다.\n",
    "  # 내부적으로 패딩 마스크도 포함되어져 있습니다.\n",
    "  look_ahead_mask = tf.keras.layers.Lambda(\n",
    "      create_look_ahead_mask,\n",
    "      output_shape=(1, None, None),\n",
    "      name='look_ahead_mask')(inputs)\n",
    "\n",
    "  # 디코더\n",
    "  dec_outputs = decoder(\n",
    "      vocab_size=vocab_size,\n",
    "      num_layers=num_layers,\n",
    "      units=units,\n",
    "      d_model=d_model,\n",
    "      num_heads=num_heads,\n",
    "      dropout=dropout,\n",
    "  )(inputs=[inputs, look_ahead_mask])\n",
    "\n",
    "  # 완전연결층\n",
    "  outputs = tf.keras.layers.Dense(units=vocab_size, name=\"outputs\")(dec_outputs)\n",
    "\n",
    "  return tf.keras.Model(inputs=inputs, outputs=outputs, name=name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "784c6826",
   "metadata": {},
   "source": [
    "**손실함수**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cea983ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#레이블인 시퀀스에 패딩이 되어 있으므로, loss를 계산할 때 패딩 마스크를 적용해야한다\n",
    "def loss_function(y_true, y_pred):\n",
    "  #y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH-1)) \n",
    "  # y_true : (batch_size, seq_len)\n",
    "  # -1 : 남은 차원은 알아서 계산\n",
    "  # seq : MAX_LENGTH - 1인 이유는 → 디코더의 정답 시퀀스는 보통 <start> 토큰 제거한 상태\n",
    "\n",
    "   \n",
    "  loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "        from_logits=True, reduction='none')(y_true, y_pred)\n",
    "    # from_logits=True: y_pred가 softmax 되기 전 값 (logits : softmax를 거치기 직전값)이기 때문\n",
    "    # → 손실 함수 내부에서 softmax를 자동으로 처리\n",
    "    # reduction='none': 손실을 일괄 평균하지 않고, 토큰마다 개별 손실 계산\n",
    "    # → 나중에 마스크를 씌워서 패딩 위치 손실은 제거할 수 있게 함\n",
    "\n",
    "  mask = tf.cast(tf.not_equal(y_true, 0), tf.float32)\n",
    "  loss = tf.multiply(loss, mask)\n",
    "    # y_true == 0인 위치는 패딩이므로 손실에서 제외. 그래서 0인 위치는 0, 나머지는 1인 마스크 생성\n",
    "\n",
    "  return tf.reduce_mean(loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1717b007",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='accuracy',     # 모니터링 대상\n",
    "    patience=3,             # 개선 없으면 몇 epoch 후에 멈출지\n",
    "    restore_best_weights=True,  # 가장 성능 좋았던 가중치를 복원할지 여부\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "150f52a1",
   "metadata": {},
   "source": [
    "**1. 모델 컴파일  및 훈련(Layer=2, D_MODEL=256)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "98ae0cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3db682a2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"gpt\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "inputs (InputLayer)             [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "look_ahead_mask (Lambda)        (None, 1, None, None 0           inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "decoder (Functional)            (None, None, 256)    3153664     inputs[0][0]                     \n",
      "                                                                 look_ahead_mask[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "outputs (Dense)                 (None, None, 8171)   2099947     decoder[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 5,253,611\n",
      "Trainable params: 5,253,611\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session() # TensorFlow에서 메모리 관리와 관련된 문제를 방지하기 위해 사용하는 함수\n",
    "                                 # Keras의 전역 상태(예: 모델, 레이어, 그래프 등)를 초기화해서 메모리를 정리\n",
    "\n",
    "# 하이퍼파라미터\n",
    "NUM_LAYERS = 2 #  디코더의 층의 개수  ( 논문 6->2)\n",
    "D_MODEL = 256 # 디코더 내부의 입, 출력의 고정 차원  (논문 512 -> 256)\n",
    "NUM_HEADS = 8 # 멀티 헤드 어텐션에서의 헤드 수 \n",
    "UNITS = 512 # 피드 포워드 신경망의 은닉층의 크기\n",
    "DROPOUT = 0.1 # 드롭아웃의 비율\n",
    "\n",
    "model_1 = gpt(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    units=UNITS,\n",
    "    d_model=D_MODEL,\n",
    "    num_heads=NUM_HEADS,\n",
    "    dropout=DROPOUT)\n",
    "\n",
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f0ab60a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type of x: <class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "for x, y in dataset.take(1):\n",
    "    print(\"type of x:\", type(x))\n",
    "   # print(\"x:\", x)\n",
    "   # print(\"y:\", y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6b0f13ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 30)\n",
      "(64, 30)\n"
     ]
    }
   ],
   "source": [
    "for x, y in dataset.take(1):\n",
    "    print(x['inputs'].shape)           # (batch_size, seq_len)\n",
    "    print(y['outputs'].shape)  # (1, seq_len, seq_len)\n",
    "   # print(y.shape)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c5b12d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = CustomSchedule(D_MODEL)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(\n",
    "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "  #y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
    "  return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n",
    "\n",
    "model_1.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0d84d9e4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "185/185 [==============================] - 25s 30ms/step - loss: 1.5385 - accuracy: 0.0668\n",
      "Epoch 2/10\n",
      "185/185 [==============================] - 6s 30ms/step - loss: 1.4031 - accuracy: 0.0706\n",
      "Epoch 3/10\n",
      "185/185 [==============================] - 6s 30ms/step - loss: 1.3793 - accuracy: 0.0713\n",
      "Epoch 4/10\n",
      "185/185 [==============================] - 6s 30ms/step - loss: 1.3660 - accuracy: 0.0716\n",
      "Epoch 5/10\n",
      "185/185 [==============================] - 6s 30ms/step - loss: 1.3557 - accuracy: 0.0719\n",
      "Epoch 6/10\n",
      "185/185 [==============================] - 6s 30ms/step - loss: 1.3487 - accuracy: 0.0723\n",
      "Epoch 7/10\n",
      "185/185 [==============================] - 6s 30ms/step - loss: 1.3401 - accuracy: 0.0724\n",
      "Epoch 8/10\n",
      "185/185 [==============================] - 6s 30ms/step - loss: 1.3329 - accuracy: 0.0728\n",
      "Epoch 9/10\n",
      "185/185 [==============================] - 6s 31ms/step - loss: 1.3252 - accuracy: 0.0734\n",
      "Epoch 10/10\n",
      "185/185 [==============================] - 6s 31ms/step - loss: 1.3157 - accuracy: 0.0737\n"
     ]
    }
   ],
   "source": [
    "#history_1 = model_1.fit(dataset, epochs=EPOCHS, verbose=1, callbacks = early_stop)\n",
    "history_1 = model_1.fit(dataset, epochs=EPOCHS, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75660576",
   "metadata": {},
   "source": [
    "## 테스트 (inference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "265ac279",
   "metadata": {},
   "source": [
    "1) 새로운 입력 문장에 대해서는 훈련 때와 동일한 전처리를 거친다.\n",
    "2) 입력 문장을 토크나이징하고, START_TOKEN과 END_TOKEN을 추가한다.\n",
    "3) 패딩 마스킹과 룩 어헤드 마스킹을 계산한다.\n",
    "4) 디코더는 입력 시퀀스로부터 다음 단어를 예측한다.\n",
    "5) 디코더는 예측된 다음 단어를 기존의 입력 시퀀스에 추가하여 새로운 입력으로 사용한다.\n",
    "6) END_TOKEN이 예측되거나 문장의 최대 길이에 도달하면 디코더는 동작을 멈춘다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "14250060",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder_inference(sentence):\n",
    "  sentence = preprocess_sentence(sentence)\n",
    "\n",
    "  # 입력된 문장을 정수 인코딩 후, 시작 토큰과 종료 토큰을 앞뒤로 추가.\n",
    "  # ex) Where have you been? → [[8331   86   30    5 1059    7 8332]]\n",
    "  sentence = tf.expand_dims(\n",
    "      START_TOKEN + tokenizer.encode(sentence) + END_TOKEN, axis=0)\n",
    "     # expand_dims : shape을 (1, sequence_length)로 만들어 배치처럼 보이게\n",
    "\n",
    "  # 디코더의 현재까지의 예측한 출력 시퀀스가 지속적으로 저장되는 변수.\n",
    "  # 처음에는 예측한 내용이 없음으로 시작 토큰만 별도 저장. ex) 8331\n",
    "  output_sequence = tf.expand_dims(START_TOKEN, 0)\n",
    "\n",
    "  # 디코더의 인퍼런스 단계\n",
    "  for i in range(MAX_LENGTH):\n",
    "    # 디코더는 최대 MAX_LENGTH의 길이만큼 다음 단어 예측을 반복합니다.\n",
    "    \n",
    "    predictions = model_1(inputs=[sentence], training=False)\n",
    "    \n",
    "    print(\"Predictions:\", predictions)\n",
    "  \n",
    "    predictions = predictions[:, -1:, :]\n",
    "    \n",
    "    # predictions : (batch_size, sequence_length, vocab_size) -> shape : (1, 1, 8333)\n",
    "    # : : 배치 전체 (1)\n",
    "    # -1:은 가장 마지막 토큰의 예측만 가져오기\n",
    "    # : : 전체 vocab에 대한 확률 (8333)\n",
    "    \n",
    "\n",
    "    # 현재 예측한 단어의 정수\n",
    "    predicted_id  = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)    # -> shape : (1,1)\n",
    "    #  tf.argmax는 int64 자료형 (자료형의 기본은 int64)\n",
    "    # output_sequece는 int32 자료형 (대부분 TesorFlow 모델은 int32로 처리)\n",
    "\n",
    "    print(\"predicted_id :\", predicted_id )\n",
    "    \n",
    "    # 만약 현재 예측한 단어가 종료 토큰이라면 for문을 종료\n",
    "    if tf.equal(predicted_id, END_TOKEN[0]):\n",
    "      break\n",
    "\n",
    "    # 예측한 단어들은 지속적으로 output_sequence에 추가됩니다.\n",
    "    # 이 output_sequence는 다시 디코더의 입력이 됩니다.\n",
    "    output_sequence = tf.concat([output_sequence, predicted_id], axis=-1)\n",
    "    \n",
    "    print(\"Output sequence:\", output_sequence)\n",
    "\n",
    "  return tf.squeeze(output_sequence, axis=0)\n",
    "\n",
    "\n",
    "def sentence_generation(sentence):\n",
    "  # 입력 문장에 대해서 디코더를 동작 시켜 예측된 정수 시퀀스를 리턴받습니다.\n",
    "  prediction = decoder_inference(sentence)\n",
    "\n",
    "  # 정수 시퀀스를 다시 텍스트 시퀀스로 변환합니다.\n",
    "  predicted_sentence = tokenizer.decode(\n",
    "      [i for i in prediction if i < tokenizer.vocab_size])\n",
    "\n",
    "  print(prediction.shape)\n",
    "  print(prediction)\n",
    "  print('입력 : {}'.format(sentence))\n",
    "  print('출력 : {}'.format(predicted_sentence))\n",
    "\n",
    "  return predicted_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "25f75d95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: tf.Tensor(\n",
      "[[[-10.761724    -3.157713    -0.47901288 ...  11.922487    -3.1919882\n",
      "   -10.813532  ]\n",
      "  [-13.087959    -2.43372     -1.3406141  ...  -1.2732797   -3.456621\n",
      "   -13.092722  ]\n",
      "  [-11.414962     2.7307777   -1.5743191  ...  -3.55031      0.69054914\n",
      "   -11.400239  ]\n",
      "  ...\n",
      "  [-14.145527     5.690526    -0.06612163 ...  -2.1844513    4.43963\n",
      "   -14.134204  ]\n",
      "  [-14.291709     6.0636454    0.35865417 ...  -2.2628279    5.2355485\n",
      "   -14.282736  ]\n",
      "  [-14.737277     6.1709967    0.9804825  ...  -2.791292     6.1949763\n",
      "   -14.713546  ]]], shape=(1, 7, 8171), dtype=float32)\n",
      "predicted_id : tf.Tensor([[8169]], shape=(1, 1), dtype=int32)\n",
      "(1,)\n",
      "tf.Tensor([8168], shape=(1,), dtype=int32)\n",
      "입력 : 내일 뭐 하고 싶어?\n",
      "출력 : \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation(\"내일 뭐 하고 싶어?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aac0932",
   "metadata": {},
   "source": [
    "## 회고 \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d88aac72",
   "metadata": {},
   "source": [
    "** Model.summary 결과\n",
    "```\n",
    "\n",
    "Model: \"gpt\"\n",
    "__________________________________________________________________________________________________\n",
    "Layer (type)                    Output Shape         Param #     Connected to                     \n",
    "==================================================================================================\n",
    "inputs (InputLayer)             [(None, None)]       0                                            \n",
    "__________________________________________________________________________________________________\n",
    "look_ahead_mask (Lambda)        (None, 1, None, None 0           inputs[0][0]                     \n",
    "__________________________________________________________________________________________________\n",
    "decoder (Functional)            (None, None, 8171)   3161835     inputs[0][0]                     \n",
    "                                                                 look_ahead_mask[0][0]            \n",
    "__________________________________________________________________________________________________\n",
    "outputs (Dense)                 (None, None, 8171)   66773412    decoder[0][0]                    \n",
    "==================================================================================================\n",
    "Total params: 69,935,247\n",
    "Trainable params: 69,935,247\n",
    "Non-trainable params: 0\n",
    "__________________________________________________________________________________________________\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce84c98",
   "metadata": {},
   "source": [
    "** model.fit 결과\n",
    "```\n",
    "Epoch 1/10\n",
    "185/185 [==============================] - 54s 277ms/step - loss: 2.1877 - accuracy: 0.0651\n",
    "Epoch 2/10\n",
    "185/185 [==============================] - 50s 269ms/step - loss: 1.8465 - accuracy: 0.0663\n",
    "Epoch 3/10\n",
    "185/185 [==============================] - 50s 271ms/step - loss: 1.6616 - accuracy: 0.0663\n",
    "Epoch 4/10\n",
    "185/185 [==============================] - 50s 272ms/step - loss: 1.5447 - accuracy: 0.0663\n",
    "Epoch 5/10\n",
    "185/185 [==============================] - 50s 273ms/step - loss: 1.4752 - accuracy: 0.0665\n",
    "Epoch 6/10\n",
    "185/185 [==============================] - 50s 271ms/step - loss: 1.4447 - accuracy: 0.0667\n",
    "Epoch 7/10\n",
    "185/185 [==============================] - 50s 271ms/step - loss: 1.4356 - accuracy: 0.0667\n",
    "Epoch 8/10\n",
    "185/185 [==============================] - 50s 271ms/step - loss: 1.4323 - accuracy: 0.0667\n",
    "Epoch 9/10\n",
    "185/185 [==============================] - 50s 272ms/step - loss: 1.4307 - accuracy: 0.0667\n",
    "Epoch 10/10\n",
    "185/185 [==============================] - 50s 272ms/step - loss: 1.4299 - accuracy: 0.0667\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
